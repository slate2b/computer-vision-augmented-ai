{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47d900f-4863-4319-a018-e0194f15650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\tev\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\tev\\anaconda3\\lib\\site-packages (10.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tev\\anaconda3\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: sentence_transformers in c:\\users\\tev\\anaconda3\\lib\\site-packages (5.2.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\tev\\anaconda3\\lib\\site-packages (1.13.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\tev\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\tev\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\tev\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from sentence_transformers) (5.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.3.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from sentence_transformers) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tev\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\tev\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tev\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from scikit-image) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\tev\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.3.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (0.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\tev\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\tev\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\tev\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (2021.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (0.7.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\tev\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\tev\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tev\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\tev\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tev\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (0.14.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\tev\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence_transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\tev\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence_transformers) (2021.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\tev\\anaconda3\\lib\\site-packages (from typer-slim->huggingface-hub>=0.20.0->sentence_transformers) (8.1.7)\n"
     ]
    }
   ],
   "source": [
    "# if running on cpu\n",
    "!pip install numpy pillow tqdm sentence_transformers faiss-cpu pandas scikit-image\n",
    "# -- OR -- \n",
    "# if running on gpu\n",
    "#!pip install numpy pillow tqdm sentence_transformers faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7757db5-c4d6-47a1-8d1e-6d359a39a3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359886a6dad647b3a118f93f1a9c5cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLIPModel LOAD REPORT from: C:\\Users\\tev\\.cache\\huggingface\\hub\\models--sentence-transformers--clip-ViT-B-32\\snapshots\\327ab6726d33c0e22f920c83f2ff9e4bd38ca37f\\0_CLIPModel\n",
      "Key                                  | Status     |  | \n",
      "-------------------------------------+------------+--+-\n",
      "text_model.embeddings.position_ids   | UNEXPECTED |  | \n",
      "vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Scanning images: 100%|█████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ./output_image_analysis/image_mapping.csv with 16 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np, pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "'''\n",
    "This notebook scans images and uses a pretrained CLIP-ViT-B-32 model to create image embeddings, compares them to the reference\n",
    "embeddings index created in the 01-create-reference-embeddings.ipynb notebook, then loads the images into a clean GUI to enable\n",
    "Human in the Loop (HITL) side-by-side image review.  This brings the Augmented AI project full circle.\n",
    "\n",
    "###\n",
    "\n",
    "This particular cell performs the AI analysis component of this Augmented AI project.  It scans images and uses a \n",
    "pretrained CLIP-ViT-B-32 model to create image embeddings, then it compares these scanned embeddings to an FAISS \n",
    "(Facebook AI Similarity Search) HNSW (Hierarchical Navigable Small World) index built using embeddings created by \n",
    "running a collection of reference images through the same pretrained CLIP model via the \n",
    "01-create-reference-embeddings.ipynb notebook.  \n",
    "\n",
    "For similarity calculations, this script uses a combination of cosine similarity and SSIM (structural similarity index) \n",
    "thumbnail comparison to identify images which are probable matches.  Through fine-tuning the configuration values, this\n",
    "comparison method can eliminate false-negatives completely and dramatically reduce false-positives.  This comparison \n",
    "approach also computes much more quicly than other methods (e.g. ORB).  \n",
    "\n",
    "The output file from this script only contains information for the input images which are determined to be reasonably\n",
    "similar to one of the reference images based on the decision thresholds.  \n",
    "'''\n",
    "\n",
    "# Retrieval / decision settings\n",
    "K = 12                              # top-k candidates retrieved from FAISS per scanned image\n",
    "EF_SEARCH = 128                     # HNSW search beam: Higher = more recall\n",
    "COS_SIM_THRESHOLD = 0.92            # cosine similarity acceptance threshold\n",
    "COS_SIM_THRESH_FOR_FALLBACK = 0.8   # minimum cosine similarity to be considered for SSIM override\n",
    "SSIM_THRESHOLD = 0.75               # SSIM acceptance threshold for SSIM override\n",
    "\n",
    "# input images filepath\n",
    "FOLDER_FOR_IMAGES_TO_ANALYZE = \"./input_channel/input_images\"\n",
    "# output filepath\n",
    "OUTPUT_FILEPATH = \"./ai_image_analysis/image_mapping.csv\"\n",
    "\n",
    "# reference\n",
    "INDEX_PATH = \"./reference_embeddings/faiss_hnsw.index\"\n",
    "REF_IMAGE_PATHS = \"./reference_embeddings/ref_image_paths.npy\"\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "model.eval()\n",
    "\n",
    "# Image types\n",
    "IMG_EXTS = (\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".tif\",\".tiff\")\n",
    "\n",
    "\n",
    "def load_image_paths(root):\n",
    "\n",
    "    return [p for p in glob.glob(os.path.join(root, \"**/*\"), recursive=True)\n",
    "            if p.lower().endswith(IMG_EXTS)]\n",
    "\n",
    "\n",
    "def pil_open_rgb(p):\n",
    "\n",
    "    try:\n",
    "        return Image.open(p).convert(\"RGB\")\n",
    "    except:\n",
    "        print(p)\n",
    "        return None\n",
    "\n",
    "\n",
    "# SSIM thumbnail comparison\n",
    "def fast_ssim(pil_a, pil_b, size=(64,64)):\n",
    "\n",
    "    A = pil_a.resize(size, Image.BICUBIC).convert(\"L\")\n",
    "    B = pil_b.resize(size, Image.BICUBIC).convert(\"L\")\n",
    "\n",
    "    # Convert to numpy uint8\n",
    "    a = np.asarray(A, dtype=np.uint8)\n",
    "    b = np.asarray(B, dtype=np.uint8)\n",
    "\n",
    "    # Use gaussian_weights for a little robustness\n",
    "    score, _ = ssim(a, b, full=True, gaussian_weights=True, use_sample_covariance=False)\n",
    "\n",
    "    return float(score)\n",
    "\n",
    "    \n",
    "# Load FAISS HNSW index & reference image paths\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "index.hnsw.efSearch = EF_SEARCH\n",
    "ref_image_paths = np.load(REF_IMAGE_PATHS, allow_pickle=True)\n",
    "\n",
    "# Load the images to be analyzed\n",
    "scan_imgs = load_image_paths(FOLDER_FOR_IMAGES_TO_ANALYZE)\n",
    "results = []\n",
    "\n",
    "for full_fpath in tqdm(scan_imgs, desc=\"Scanning images\"):\n",
    "    split_fname = full_fpath.split(\"\\\\\")\n",
    "    num_elements_split_fname = len(split_fname)\n",
    "    fname = split_fname[num_elements_split_fname - 1]\n",
    "    split_fpath = full_fpath.split(\"/\")\n",
    "    num_elements_split_fpath = len(split_fpath)\n",
    "    partial_fpath = split_fpath[num_elements_split_fpath - 1]\n",
    "    input_img = pil_open_rgb(full_fpath)\n",
    "    if input_img is None:\n",
    "        continue\n",
    "\n",
    "    # batch_imgs can be a list of PIL Images, NumPy arrays, or image file paths\n",
    "    input_img_vec = model.encode(\n",
    "        input_img,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,  # L2 normalize\n",
    "        show_progress_bar=False,\n",
    "        batch_size=32,  # adjust to your GPU/CPU memory\n",
    "    ).astype(\"float32\").reshape(1, -1)\n",
    "\n",
    "    # Retrieve top-k candidates from the image catalog\n",
    "    D, I = index.search(input_img_vec, K)  # inner product on normalized vectors == cosine similarity\n",
    "    sims = D[0]\n",
    "    idxs = I[0]\n",
    "\n",
    "    # Pick the best candidate that satisfies the similarity threshold\n",
    "    best = None\n",
    "    best_sim = -1.0\n",
    "\n",
    "    for sim, cand_idx in zip(sims, idxs):\n",
    "        if cand_idx < 0:\n",
    "            continue\n",
    "        cand_path = str(ref_image_paths[cand_idx])\n",
    "\n",
    "        # Calculate thumbnail SSIM score\n",
    "        cand_img = pil_open_rgb(cand_path)\n",
    "        ssim_score = fast_ssim(input_img, cand_img)\n",
    "\n",
    "        split_cand_fname = cand_path.split(\"\\\\\")\n",
    "        num_elements_split_cand_fname = len(split_cand_fname)\n",
    "        cand_fname = split_cand_fname[num_elements_split_cand_fname - 1]\n",
    "\n",
    "        if sim >= COS_SIM_THRESHOLD and sim >= best_sim:\n",
    "            # Accept on similarity alone\n",
    "            best = (cand_fname, float(sim), ssim_score)\n",
    "            best_sim = float(sim)\n",
    "\n",
    "        # SSIM fallback for near-threshold cases\n",
    "        if best is None and sim >= COS_SIM_THRESH_FOR_FALLBACK:\n",
    "            if cand_img is None:\n",
    "                continue\n",
    "            if ssim_score >= SSIM_THRESHOLD:\n",
    "                best = (cand_fname, float(sim), ssim_score)\n",
    "                best_sim = float(sim)\n",
    "\n",
    "    if best is not None:\n",
    "        results.append({\n",
    "            \"input_filename\": fname,\n",
    "            \"match_filename\": best[0],\n",
    "            \"cosine_similarity\": best[1],\n",
    "            \"thumbnail_ssim\": best[2],\n",
    "            \"input_filepath\": partial_fpath\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(OUTPUT_FILEPATH, index=False)\n",
    "print(f\"Wrote {OUTPUT_FILEPATH} with {len(df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "661cf65f-cb02-4e44-a047-d122d29b4fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 1066.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "'''\n",
    "This cell acts as the bridge between the AI side of this project and the Human in the Loop (HITL). It copies the \n",
    "images which the previous cell (via the CLIP ViT model) determined to be possible matches into a folder that\n",
    "will be used by the next cell to present images to a human user for final visual review.   \n",
    "'''\n",
    "\n",
    "input_channel_dir = \"./input_channel\"\n",
    "possible_matches_input_file = \"./ai_image_analysis/image_mapping.csv\"\n",
    "input_image_dir = \"input_images\"\n",
    "destination_image_dir = \"./possible_matching_images\"\n",
    "input_image_folder_name = input_image_dir\n",
    "\n",
    "# Create destination folder\n",
    "if not os.path.exists(destination_image_dir):\n",
    "    os.makedirs(destination_image_dir)\n",
    "    print(f\"Directory '{destination_image_dir}' created.\")\n",
    "\n",
    "# reading input file\n",
    "data = pd.read_csv(possible_matches_input_file, encoding='utf-8')\n",
    "data = data.squeeze()\n",
    "\n",
    "base_image_counts = {}\n",
    "for class_folder in os.listdir(input_channel_dir):\n",
    "    print(class_folder)\n",
    "    class_path = os.path.join(input_channel_dir, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "        num_images = len(os.listdir(class_path))\n",
    "        base_image_counts[class_folder] = num_images\n",
    "\n",
    "image_counter = 0\n",
    "images_copied_counter = 0\n",
    "is_end_of_files = False\n",
    "\n",
    "input_image_dir_list = os.listdir(input_channel_dir + \"/\" + input_image_dir)\n",
    "input_image_dir_list.sort()  # otherwise lowercase and uppercase would get sorted differently from ImageFolder\n",
    "\n",
    "for image in tqdm(input_image_dir_list):\n",
    "\n",
    "    if image_counter >= (len(input_image_dir_list)):\n",
    "        is_end_of_files = True\n",
    "        print(\"end of files\")\n",
    "\n",
    "    if is_end_of_files:\n",
    "        break\n",
    "\n",
    "    fname = image\n",
    "\n",
    "    # if there is only a single filename in the input file, data will be a string instead of a pandas series\n",
    "    if type(data) == str:\n",
    "\n",
    "        if data == fname:\n",
    "\n",
    "            input_fpath = input_channel_dir + \"/\" + input_image_dir + \"/\" + fname\n",
    "            output_fpath = destination_image_dir + \"/\" + fname\n",
    "\n",
    "            try:\n",
    "                shutil.copy2(input_fpath, output_fpath)\n",
    "                images_copied_counter += 1\n",
    "\n",
    "            except OSError:\n",
    "                print(\"Problem copying: {}\".format(input_fpath))\n",
    "\n",
    "    # otherwise data will be a pandas series and the following code will manage multiple images\n",
    "    else:\n",
    "\n",
    "        for name in data[\"input_filename\"]:\n",
    "\n",
    "            if name == fname:\n",
    "\n",
    "                input_fpath = input_channel_dir + \"/\" + input_image_dir + \"/\" + fname\n",
    "                output_fpath = destination_image_dir + \"/\" + fname\n",
    "\n",
    "                try:\n",
    "                    shutil.copy2(input_fpath, output_fpath)\n",
    "                    images_copied_counter += 1\n",
    "\n",
    "                except OSError:\n",
    "                    print(\"Problem copying: {}\".format(input_fpath))\n",
    "\n",
    "    image_counter += 1\n",
    "\n",
    "print(\"\\nSuccess!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5cd75e6-63db-4401-9cbe-107efdf24cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tkinter as tk\n",
    "from tkinter.ttk import Progressbar\n",
    "from PIL import ImageTk, Image\n",
    "from threading import Thread\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "This cell closes the loop on the this HITL AI Image Retrieval project. It loads the images which were identified earlier \n",
    "in this notebook as possible matches alongside the best matching reference image an easy to use GUI that \n",
    "allows a human user to determine whether the input images are true matches.  The feedback from the user is then saved\n",
    "as an output file which allows downstream workflows to locate the matching files.  \n",
    "'''\n",
    "\n",
    "start_image_counter = 1\n",
    "\n",
    "input_channel_dir = \"./input_channel\"\n",
    "input_image_dir = \"input_images\"  # NEED THE ACTUAL FOLDER -- NOT A NESTING INPUT FOLDER\n",
    "reference_image_dir = \"./reference_images\" # NEED THE ACTUAL FOLDER -- NOT A NESTING INPUT FOLDER\n",
    "input_image_fpath = input_channel_dir + \"/\" + input_image_dir\n",
    "possible_matches_input_file = \"./ai_image_analysis/image_mapping.csv\"\n",
    "output_dir = \"./hitl_output\"\n",
    "\n",
    "image_counter = start_image_counter - 1\n",
    "visual_review_image_filenames = []\n",
    "visual_review_feedback = []\n",
    "visual_review_image_filepaths = []\n",
    "visual_review_matching_filenames = []\n",
    "\n",
    "input_data = pd.read_csv(possible_matches_input_file)\n",
    "input_image_filenames = input_data['input_filename'].tolist()\n",
    "match_image_filenames = input_data['match_filename'].tolist()\n",
    "input_image_filepaths = input_data['input_filepath'].tolist()\n",
    "\n",
    "finished_pruning_filenames = False\n",
    "\n",
    "while not finished_pruning_filenames:\n",
    "\n",
    "    highest_index_so_far = 0\n",
    "\n",
    "    for i in range(len(match_image_filenames)):\n",
    "\n",
    "        highest_index_so_far = i\n",
    "\n",
    "        if type(match_image_filenames[i]) == float:\n",
    "\n",
    "            input_image_filenames.pop(i)\n",
    "            match_image_filenames.pop(i)\n",
    "            input_image_filepaths.pop(i)\n",
    "            break\n",
    "\n",
    "    if highest_index_so_far == len(match_image_filenames) - 1:\n",
    "        finished_pruning_filenames = True\n",
    "\n",
    "# # IF THE FILENAMES DON'T HAVE \"small_variant\" in front...\n",
    "# for i in range(len(match_image_filenames)):\n",
    "#     match_image_filenames[i] = \"small_variant_\" + str(match_image_filenames[i])\n",
    "\n",
    "num_input_files = len(input_image_filenames)\n",
    "\n",
    "\"\"\"\n",
    "Configuring GUI\n",
    "\"\"\"\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title(\"Augmented AI Review\")\n",
    "\n",
    "window.rowconfigure(0, minsize=50, weight=0)\n",
    "window.rowconfigure(1, minsize=50, weight=0)\n",
    "window.columnconfigure(0, minsize=600, weight=1)\n",
    "\n",
    "frm_greeting = tk.Frame(window, bd=0)\n",
    "frm_progress = tk.Frame(window, bd=0)\n",
    "frm_finished = tk.Frame(window, bd=0)\n",
    "frm_image_banner = tk.Frame(window, bd=0)\n",
    "frm_image_display = tk.Frame(window, bd=0)\n",
    "frm_user_input_button = tk.Frame(window, bd=0)\n",
    "frm_user_input_processing = tk.Frame(window, bd=0)\n",
    "frm_counter = tk.Frame(window, bd=0)\n",
    "\n",
    "frm_greeting.rowconfigure(0, minsize=50, weight=0)\n",
    "frm_greeting.columnconfigure(0, minsize=400, weight=1)\n",
    "\n",
    "frm_progress.rowconfigure(0, minsize=50, weight=0)\n",
    "frm_progress.columnconfigure(0, minsize=400, weight=1)\n",
    "\n",
    "frm_finished.rowconfigure(0, minsize=50, weight=0)\n",
    "frm_finished.columnconfigure(0, minsize=400, weight=1)\n",
    "\n",
    "frm_image_banner.rowconfigure(0, minsize=50, weight=0)\n",
    "frm_image_banner.columnconfigure(0, minsize=50, weight=1)\n",
    "frm_image_banner.columnconfigure(1, minsize=250, weight=0)\n",
    "frm_image_banner.columnconfigure(2, minsize=250, weight=0)\n",
    "frm_image_banner.columnconfigure(3, minsize=50, weight=1)\n",
    "\n",
    "frm_image_display.rowconfigure(0, minsize=250, weight=0)\n",
    "frm_image_display.columnconfigure(0, minsize=50, weight=10)\n",
    "frm_image_display.columnconfigure(1, minsize=250, weight=0)\n",
    "frm_image_display.columnconfigure(2, minsize=250, weight=0)\n",
    "frm_image_display.columnconfigure(3, minsize=50, weight=10)\n",
    "\n",
    "frm_user_input_button.rowconfigure(0, minsize=50, weight=0)\n",
    "frm_user_input_button.rowconfigure(1, minsize=15, weight=0)\n",
    "frm_user_input_button.columnconfigure(0, minsize=100, weight=1)\n",
    "frm_user_input_button.columnconfigure(1, minsize=90, weight=0)\n",
    "frm_user_input_button.columnconfigure(2, minsize=40, weight=0)\n",
    "frm_user_input_button.columnconfigure(3, minsize=90, weight=0)\n",
    "frm_user_input_button.columnconfigure(4, minsize=90, weight=1)\n",
    "frm_user_input_button.columnconfigure(5, minsize=90, weight=0)\n",
    "frm_user_input_button.columnconfigure(6, minsize=100, weight=1)\n",
    "\n",
    "frm_counter.rowconfigure(0, minsize=50, weight=0)\n",
    "frm_counter.columnconfigure(0, minsize=150, weight=1)\n",
    "frm_counter.columnconfigure(1, minsize=40, weight=0)\n",
    "frm_counter.columnconfigure(2, minsize=20, weight=0)\n",
    "frm_counter.columnconfigure(3, minsize=40, weight=0)\n",
    "frm_counter.columnconfigure(4, minsize=150, weight=1)\n",
    "\n",
    "lbl_greeting = tk.Label(frm_greeting,\n",
    "                        text=\"Review images below and click the appropriate button.\",\n",
    "                        font=(\"Arial\", 14))\n",
    "lbl_greeting.grid(row=0, column=0, sticky=\"nsew\", padx=25, pady=25)\n",
    "\n",
    "progressbar = Progressbar(frm_progress, mode=\"indeterminate\")\n",
    "\n",
    "lbl_finished = tk.Label(frm_finished, text=\"Processing completed!  Output file saved in Output_Files folder.\",\n",
    "                        foreground=\"green\", font=(\"Arial\", 12))\n",
    "\n",
    "lbl_input_image = tk.Label(frm_image_banner, text=\"Input Image\", font=(\"Arial\", 12))\n",
    "lbl_input_image.grid(row=0, column=1, sticky=\"nsew\", padx=15, pady=15)\n",
    "lbl_match_image = tk.Label(frm_image_banner, text=\"Possible Match\", font=(\"Arial\", 12))\n",
    "lbl_match_image.grid(row=0, column=2, sticky=\"nsew\", padx=15, pady=15)\n",
    "\n",
    "input_image = ImageTk.PhotoImage(Image.open(input_image_fpath + \"/\" + input_image_filenames[image_counter]).resize((250, 250)))\n",
    "input_image_panel = tk.Label(frm_image_display, image=input_image)\n",
    "input_image_panel.grid(row=0, column=1, sticky=\"nsew\", padx=15, pady=15)\n",
    "\n",
    "try:\n",
    "    match_image = ImageTk.PhotoImage(Image.open(reference_image_dir + \"/\" + match_image_filenames[image_counter] + \".jpg\").resize((250, 250)))\n",
    "except:\n",
    "    match_image = ImageTk.PhotoImage(Image.open(reference_image_dir + \"/\" + match_image_filenames[image_counter]).resize((250, 250)))\n",
    "match_image_panel = tk.Label(frm_image_display, image=match_image)\n",
    "match_image_panel.grid(row=0, column=2, sticky=\"nsew\", padx=15, pady=15)\n",
    "\n",
    "counter_current = tk.Label(frm_counter, text=\"1\", font=(\"Arial\", 12))\n",
    "counter_current.grid(row=0, column=1, sticky=\"new\", padx=5, pady=5)\n",
    "counter_of = tk.Label(frm_counter, text=\"of\", font=(\"Arial\", 12))\n",
    "counter_of.grid(row=0, column=2, sticky=\"new\", padx=5, pady=5)\n",
    "counter_total = tk.Label(frm_counter, text=num_input_files, font=(\"Arial\", 12))\n",
    "counter_total.grid(row=0, column=3, sticky=\"new\", padx=5, pady=5)\n",
    "\n",
    "btn_back = tk.Button(frm_user_input_button, text=\"Back\", border=4)\n",
    "btn_back.grid(row=0, column=1, sticky=\"nsew\", padx=10, pady=5)\n",
    "\n",
    "btn_match = tk.Button(frm_user_input_button, text=\"Match\", border=4)\n",
    "btn_match.grid(row=0, column=3, sticky=\"nsew\", padx=10, pady=5)\n",
    "\n",
    "btn_not_match = tk.Button(frm_user_input_button, text=\"Not a Match\", border=4)\n",
    "btn_not_match.grid(row=0, column=4, sticky=\"nsew\", padx=10, pady=5)\n",
    "\n",
    "btn_save = tk.Button(frm_user_input_button, text=\"Save File\", border=4)\n",
    "btn_save.grid(row=0, column=5, sticky=\"nsew\", padx=10, pady=5)\n",
    "\n",
    "\n",
    "def go_back():\n",
    "    \"\"\"\n",
    "    Predicts the PIM Group for product data entered through GUI from user.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "\n",
    "    window.update_idletasks()\n",
    "\n",
    "\n",
    "def process_go_back():\n",
    "    \"\"\"\n",
    "    Prepares data entered by user through the GUI and calls the predict_from_input\n",
    "    function in a separate thread.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "    global btn_back\n",
    "    global btn_match\n",
    "    global btn_not_match\n",
    "    global btn_save\n",
    "    global image_counter\n",
    "\n",
    "    window.update_idletasks()\n",
    "\n",
    "    frm_finished.grid_remove()\n",
    "\n",
    "    if image_counter > 0:\n",
    "\n",
    "        btn_back[\"state\"] = \"disabled\"\n",
    "        btn_match[\"state\"] = \"disabled\"\n",
    "        btn_not_match[\"state\"] = \"disabled\"\n",
    "        btn_save[\"state\"] = \"disabled\"\n",
    "\n",
    "        image_counter -= 1\n",
    "\n",
    "        t = Thread(target=go_back)\n",
    "        t.start()\n",
    "\n",
    "        schedule_check_go_back(t)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def schedule_check_go_back(thread):\n",
    "    \"\"\"\n",
    "    Schedules the execution of the check_if_done_input function each\n",
    "    second.\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "\n",
    "    window.after(200, check_if_done_go_back, thread)\n",
    "\n",
    "\n",
    "def check_if_done_go_back(thread):\n",
    "    \"\"\"\n",
    "    Checks to see if the thread on which the predict_from_input function is\n",
    "    running and handles actions to be executed upon completion.\n",
    "\n",
    "    :param thread: The thread on which the predict_from_input function is running\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "    global btn_match\n",
    "    global btn_not_match\n",
    "    global btn_save\n",
    "    global image_counter\n",
    "    global input_image_filenames\n",
    "    global input_image_filepaths\n",
    "    global input_image\n",
    "    global match_image\n",
    "    global input_image_panel\n",
    "    global match_image_panel\n",
    "    global counter_current\n",
    "\n",
    "    if not thread.is_alive():\n",
    "\n",
    "        progressbar.stop()\n",
    "        frm_progress.grid_remove()\n",
    "        frm_finished.grid(row=2, column=0, sticky=\"nsew\")\n",
    "\n",
    "        if image_counter > 0:\n",
    "            # pop the user feedback for the previous image pair from the filenames and feedback lists\n",
    "            visual_review_image_filenames.pop(image_counter + 1 - start_image_counter)  # handles starting with different image\n",
    "            visual_review_feedback.pop(image_counter - start_image_counter)  # handles starting with different image\n",
    "            visual_review_image_filepaths.pop(image_counter + 1 - start_image_counter)  # handles starting with different image\n",
    "            visual_review_matching_filenames.pop(image_counter + 1 - start_image_counter)  # handles starting with different image\n",
    "\n",
    "        if image_counter == num_input_files:\n",
    "            process_save_progress()\n",
    "\n",
    "        if not image_counter >= num_input_files:\n",
    "            btn_back[\"state\"] = \"normal\"\n",
    "            btn_match[\"state\"] = \"normal\"\n",
    "            btn_not_match[\"state\"] = \"normal\"\n",
    "            btn_save[\"state\"] = \"normal\"\n",
    "\n",
    "            input_image = ImageTk.PhotoImage(\n",
    "                Image.open(input_image_fpath + \"/\" + input_image_filenames[image_counter]).resize((250, 250)))\n",
    "            input_image_panel = tk.Label(frm_image_display, image=input_image)\n",
    "            input_image_panel.grid(row=0, column=1, sticky=\"nsew\", padx=15, pady=15)\n",
    "            try:\n",
    "                match_image = ImageTk.PhotoImage(\n",
    "                    Image.open(reference_image_dir + \"/\" + match_image_filenames[image_counter] + \".jpg\").resize(\n",
    "                        (250, 250)))\n",
    "            except:\n",
    "                match_image = ImageTk.PhotoImage(\n",
    "                    Image.open(reference_image_dir + \"/\" + match_image_filenames[image_counter]).resize((250, 250)))\n",
    "            # match_image = ImageTk.PhotoImage(\n",
    "            #     Image.open(match_image_dir + \"/\" + match_image_filenames[image_counter] + \".jpg\").resize((250, 250)))\n",
    "            match_image_panel = tk.Label(frm_image_display, image=match_image)\n",
    "            match_image_panel.grid(row=0, column=2, sticky=\"nsew\", padx=15, pady=15)\n",
    "            counter_current = tk.Label(frm_counter, text=str(image_counter + 1), font=(\"Arial\", 12))\n",
    "            counter_current.grid(row=0, column=1, sticky=\"new\", padx=5, pady=5)\n",
    "\n",
    "    else:\n",
    "        # Otherwise check again after .2 seconds.\n",
    "        schedule_check_go_back(thread)\n",
    "\n",
    "\n",
    "def flag_match():\n",
    "    \"\"\"\n",
    "    Predicts the PIM Group for product data entered through GUI from user.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "\n",
    "    window.update_idletasks()\n",
    "\n",
    "\n",
    "def process_flag_match():\n",
    "    \"\"\"\n",
    "    Prepares data entered by user through the GUI and calls the predict_from_input\n",
    "    function in a separate thread.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "    global btn_back\n",
    "    global btn_match\n",
    "    global btn_not_match\n",
    "    global btn_save\n",
    "    global image_counter\n",
    "\n",
    "    window.update_idletasks()\n",
    "\n",
    "    frm_finished.grid_remove()\n",
    "\n",
    "    btn_back[\"state\"] = \"disabled\"\n",
    "    btn_match[\"state\"] = \"disabled\"\n",
    "    btn_not_match[\"state\"] = \"disabled\"\n",
    "    btn_save[\"state\"] = \"disabled\"\n",
    "\n",
    "    image_counter += 1\n",
    "\n",
    "    t = Thread(target=flag_match)\n",
    "    t.start()\n",
    "\n",
    "    schedule_check_flag_match(t)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def schedule_check_flag_match(thread):\n",
    "    \"\"\"\n",
    "    Schedules the execution of the check_if_done_input function each\n",
    "    second.\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "\n",
    "    window.after(200, check_if_done_flag_match, thread)\n",
    "\n",
    "\n",
    "def check_if_done_flag_match(thread):\n",
    "    \"\"\"\n",
    "    Checks to see if the thread on which the predict_from_input function is\n",
    "    running and handles actions to be executed upon completion.\n",
    "\n",
    "    :param thread: The thread on which the predict_from_input function is running\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "    global btn_match\n",
    "    global btn_not_match\n",
    "    global btn_save\n",
    "    global image_counter\n",
    "    global input_image_filenames\n",
    "    global input_image_filepaths\n",
    "    global input_image\n",
    "    global input_image_panel\n",
    "    global match_image\n",
    "    global match_image_panel\n",
    "\n",
    "    if not thread.is_alive():\n",
    "\n",
    "        progressbar.stop()\n",
    "        frm_progress.grid_remove()\n",
    "        frm_finished.grid(row=2, column=0, sticky=\"nsew\")\n",
    "\n",
    "        visual_review_image_filenames.append(input_image_filenames[image_counter - 1])\n",
    "        visual_review_feedback.append(\"match\")\n",
    "        visual_review_image_filepaths.append(input_image_filepaths[image_counter - 1])\n",
    "        visual_review_matching_filenames.append(match_image_filenames[image_counter - 1])\n",
    "\n",
    "        if image_counter == num_input_files:\n",
    "            process_save_progress()\n",
    "\n",
    "        if not image_counter >= num_input_files:\n",
    "\n",
    "            if type(match_image_filenames[image_counter - 1]) != float:\n",
    "\n",
    "                btn_back[\"state\"] = \"normal\"\n",
    "                btn_match[\"state\"] = \"normal\"\n",
    "                btn_not_match[\"state\"] = \"normal\"\n",
    "                btn_save[\"state\"] = \"normal\"\n",
    "\n",
    "                input_image = ImageTk.PhotoImage(\n",
    "                    Image.open(input_image_fpath + \"/\" + input_image_filenames[image_counter]).resize((250, 250)))\n",
    "                input_image_panel = tk.Label(frm_image_display, image=input_image)\n",
    "                input_image_panel.grid(row=0, column=1, sticky=\"nsew\", padx=15, pady=15)\n",
    "                try:\n",
    "                    match_image = ImageTk.PhotoImage(\n",
    "                        Image.open(reference_image_dir + \"/\" + match_image_filenames[image_counter] + \".jpg\").resize(\n",
    "                            (250, 250)))\n",
    "                except:\n",
    "                    match_image = ImageTk.PhotoImage(\n",
    "                        Image.open(reference_image_dir + \"/\" + match_image_filenames[image_counter]).resize((250, 250)))\n",
    "                # match_image = ImageTk.PhotoImage(\n",
    "                #     Image.open(match_image_dir + \"/\" + match_image_filenames[image_counter] + \".jpg\").resize((250, 250)))\n",
    "                match_image_panel = tk.Label(frm_image_display, image=match_image)\n",
    "                match_image_panel.grid(row=0, column=2, sticky=\"nsew\", padx=15, pady=15)\n",
    "                counter_current = tk.Label(frm_counter, text=str(image_counter + 1), font=(\"Arial\", 12))\n",
    "                counter_current.grid(row=0, column=1, sticky=\"new\", padx=5, pady=5)\n",
    "            else:\n",
    "\n",
    "                btn_back[\"state\"] = \"normal\"\n",
    "                btn_match[\"state\"] = \"normal\"\n",
    "                btn_not_match[\"state\"] = \"normal\"\n",
    "                btn_save[\"state\"] = \"normal\"\n",
    "\n",
    "                image_counter += 1\n",
    "\n",
    "    else:\n",
    "        # Otherwise check again after .2 seconds.\n",
    "        schedule_check_flag_match(thread)\n",
    "\n",
    "\n",
    "def flag_not_match():\n",
    "    \"\"\"\n",
    "    Predicts the PIM Group for product data entered through GUI from user.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "\n",
    "    window.update_idletasks()\n",
    "\n",
    "\n",
    "def process_flag_not_match():\n",
    "    \"\"\"\n",
    "    Prepares data entered by user through the GUI and calls the predict_from_input\n",
    "    function in a separate thread.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "    global btn_back\n",
    "    global btn_match\n",
    "    global btn_not_match\n",
    "    global btn_save\n",
    "    global image_counter\n",
    "\n",
    "    window.update_idletasks()\n",
    "\n",
    "    frm_finished.grid_remove()\n",
    "\n",
    "    btn_back[\"state\"] = \"disabled\"\n",
    "    btn_match[\"state\"] = \"disabled\"\n",
    "    btn_not_match[\"state\"] = \"disabled\"\n",
    "    btn_save[\"state\"] = \"disabled\"\n",
    "\n",
    "    image_counter += 1\n",
    "\n",
    "    t = Thread(target=flag_not_match)\n",
    "    t.start()\n",
    "\n",
    "    schedule_check_flag_not_match(t)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def schedule_check_flag_not_match(thread):\n",
    "    \"\"\"\n",
    "    Schedules the execution of the check_if_done_input function each\n",
    "    second.\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "\n",
    "    window.after(200, check_if_done_flag_not_match, thread)\n",
    "\n",
    "\n",
    "def check_if_done_flag_not_match(thread):\n",
    "    \"\"\"\n",
    "    Checks to see if the thread on which the predict_from_input function is\n",
    "    running and handles actions to be executed upon completion.\n",
    "\n",
    "    :param thread: The thread on which the predict_from_input function is running\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "    global btn_match\n",
    "    global btn_not_match\n",
    "    global btn_save\n",
    "    global image_counter\n",
    "    global input_image_filenames\n",
    "    global input_image\n",
    "    global match_image\n",
    "    global input_image_panel\n",
    "    global match_image_panel\n",
    "    global counter_current\n",
    "\n",
    "    if not thread.is_alive():\n",
    "\n",
    "        progressbar.stop()\n",
    "        frm_progress.grid_remove()\n",
    "        frm_finished.grid(row=2, column=0, sticky=\"nsew\")\n",
    "\n",
    "        visual_review_image_filenames.append(input_image_filenames[image_counter - 1])\n",
    "        visual_review_feedback.append(\"not a match\")\n",
    "        visual_review_image_filepaths.append(input_image_filepaths[image_counter - 1])\n",
    "        visual_review_matching_filenames.append(match_image_filenames[image_counter - 1])\n",
    "\n",
    "        if image_counter == num_input_files:\n",
    "            process_save_progress()\n",
    "\n",
    "        if not image_counter >= num_input_files:\n",
    "            btn_back[\"state\"] = \"normal\"\n",
    "            btn_match[\"state\"] = \"normal\"\n",
    "            btn_not_match[\"state\"] = \"normal\"\n",
    "            btn_save[\"state\"] = \"normal\"\n",
    "\n",
    "            input_image = ImageTk.PhotoImage(\n",
    "                Image.open(input_image_fpath + \"/\" + input_image_filenames[image_counter]).resize((250, 250)))\n",
    "            input_image_panel = tk.Label(frm_image_display, image=input_image)\n",
    "            input_image_panel.grid(row=0, column=1, sticky=\"nsew\", padx=15, pady=15)\n",
    "            try:\n",
    "                match_image = ImageTk.PhotoImage(\n",
    "                    Image.open(reference_image_dir + \"/\" + match_image_filenames[image_counter] + \".jpg\").resize(\n",
    "                        (250, 250)))\n",
    "            except:\n",
    "                match_image = ImageTk.PhotoImage(\n",
    "                    Image.open(reference_image_dir + \"/\" + match_image_filenames[image_counter]).resize((250, 250)))\n",
    "            # match_image = ImageTk.PhotoImage(\n",
    "            #     Image.open(match_image_dir + \"/\" + match_image_filenames[image_counter] + \".jpg\").resize((250, 250)))\n",
    "            match_image_panel = tk.Label(frm_image_display, image=match_image)\n",
    "            match_image_panel.grid(row=0, column=2, sticky=\"nsew\", padx=15, pady=15)\n",
    "            counter_current = tk.Label(frm_counter, text=str(image_counter + 1), font=(\"Arial\", 12))\n",
    "            counter_current.grid(row=0, column=1, sticky=\"new\", padx=5, pady=5)\n",
    "\n",
    "    else:\n",
    "        # Otherwise check again after .2 seconds.\n",
    "        schedule_check_flag_not_match(thread)\n",
    "\n",
    "\n",
    "def save_progress():\n",
    "    \"\"\"\n",
    "    Predicts the PIM Group for product data entered through GUI from user.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "\n",
    "    window.update_idletasks()\n",
    "\n",
    "\n",
    "def process_save_progress():\n",
    "    \"\"\"\n",
    "    Prepares data entered by user through the GUI and calls the predict_from_input\n",
    "    function in a separate thread.\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "    global btn_back\n",
    "    global btn_match\n",
    "    global btn_not_match\n",
    "    global btn_save\n",
    "    global image_counter\n",
    "    global lbl_greeting\n",
    "\n",
    "    window.update_idletasks()\n",
    "\n",
    "    frm_image_banner.grid_remove()\n",
    "    frm_image_display.grid_remove()\n",
    "\n",
    "    frm_progress.grid(row=1, column=0, sticky=\"nsew\")\n",
    "    progressbar.start()\n",
    "\n",
    "    if image_counter == num_input_files - 1:\n",
    "\n",
    "        lbl_greeting = tk.Label(frm_greeting,\n",
    "                                text=\"End of files, saving user feedback...\",\n",
    "                                font=(\"Arial\", 14))\n",
    "        lbl_greeting.grid(row=0, column=0, sticky=\"nsew\", padx=25, pady=25)\n",
    "    else:\n",
    "        lbl_greeting = tk.Label(frm_greeting,\n",
    "                                text=\"Saving user feedback...\",\n",
    "                                font=(\"Arial\", 14))\n",
    "        lbl_greeting.grid(row=0, column=0, sticky=\"nsew\", padx=25, pady=25)\n",
    "\n",
    "    btn_back[\"state\"] = \"disabled\"\n",
    "    btn_match[\"state\"] = \"disabled\"\n",
    "    btn_not_match[\"state\"] = \"disabled\"\n",
    "    btn_save[\"state\"] = \"disabled\"\n",
    "\n",
    "    image_counter += 1\n",
    "\n",
    "    t = Thread(target=save_progress)\n",
    "    t.start()\n",
    "\n",
    "    schedule_check_save_progress(t)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def schedule_check_save_progress(thread):\n",
    "    \"\"\"\n",
    "    Schedules the execution of the check_if_done_input function each\n",
    "    second.\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "\n",
    "    window.after(1500, check_if_done_save_progress, thread)\n",
    "\n",
    "\n",
    "def check_if_done_save_progress(thread):\n",
    "    \"\"\"\n",
    "    Checks to see if the thread on which the predict_from_input function is\n",
    "    running and handles actions to be executed upon completion.\n",
    "\n",
    "    :param thread: The thread on which the predict_from_input function is running\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    global window\n",
    "    global btn_back\n",
    "    global btn_match\n",
    "    global btn_not_match\n",
    "    global btn_save\n",
    "    global image_counter\n",
    "    global input_image_filenames\n",
    "    global lbl_greeting\n",
    "\n",
    "    if not thread.is_alive():\n",
    "\n",
    "        progressbar.stop()\n",
    "        frm_progress.grid_remove()\n",
    "\n",
    "        lbl_greeting = tk.Label(frm_greeting,\n",
    "                                text=\"Save completed\",\n",
    "                                font=(\"Arial\", 14))\n",
    "        lbl_greeting.grid(row=0, column=0, sticky=\"nsew\", padx=25, pady=25)\n",
    "\n",
    "        visual_review_image_filenames_series = pd.Series(visual_review_image_filenames)\n",
    "        visual_review_feedback_series = pd.Series(visual_review_feedback)\n",
    "        visual_review_image_filepaths_series = pd.Series(visual_review_image_filepaths)\n",
    "        visual_review_matching_image_filepaths_series = pd.Series(visual_review_matching_filenames)\n",
    "        visual_results_df = pd.DataFrame(columns=['input_filename', 'input_filepath', 'user_feedback',\n",
    "                                                  'potential_match_reference_filename'])\n",
    "        visual_results_df['input_filename'] = visual_review_image_filenames_series\n",
    "        visual_results_df['input_filepath'] = visual_review_image_filepaths_series\n",
    "        visual_results_df['user_feedback'] = visual_review_feedback_series\n",
    "        visual_results_df['potential_match_reference_filename'] = visual_review_matching_image_filepaths_series\n",
    "\n",
    "        visual_results_df.to_csv(path_or_buf=output_dir + \"/hitl_output_\" +\n",
    "                                             str(datetime.now().strftime('%Y-%m-%d_%H.%M.%S')) +\n",
    "                                             '.csv', sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "        btn_back[\"state\"] = \"disabled\"\n",
    "        btn_match[\"state\"] = \"disabled\"\n",
    "        btn_not_match[\"state\"] = \"disabled\"\n",
    "        btn_save[\"state\"] = \"disabled\"\n",
    "\n",
    "    else:\n",
    "        # Otherwise check again after one second.\n",
    "        schedule_check_save_progress(thread)\n",
    "\n",
    "btn_back = tk.Button(frm_user_input_button, text=\"Back\", border=4, command=process_go_back)\n",
    "btn_back.grid(row=0, column=1, sticky=\"nsew\", padx=10, pady=5)\n",
    "\n",
    "btn_match = tk.Button(frm_user_input_button, text=\"Match\", border=4, command=process_flag_match)\n",
    "btn_match.grid(row=0, column=3, sticky=\"nsew\", padx=10, pady=5)\n",
    "\n",
    "btn_not_match = tk.Button(frm_user_input_button, text=\"Not a Match\", border=4, command=process_flag_not_match)\n",
    "btn_not_match.grid(row=0, column=4, sticky=\"nsew\", padx=10, pady=5)\n",
    "\n",
    "btn_save = tk.Button(frm_user_input_button, text=\"Save File\", border=4, command=process_save_progress)\n",
    "btn_save.grid(row=0, column=5, sticky=\"nsew\", padx=10, pady=5)\n",
    "\n",
    "frm_greeting.grid(row=0, column=0, sticky=\"nsew\")\n",
    "frm_image_banner.grid(row=1, column=0, sticky=\"nsew\")\n",
    "frm_image_display.grid(row=2, column=0, sticky=\"nsew\")\n",
    "frm_user_input_button.grid(row=3, column=0, sticky=\"nsew\")\n",
    "frm_counter.grid(row=4, column=0, sticky=\"nsew\", pady=10)\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6657bf9-5c6c-473e-bc9a-18f6768aebc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
