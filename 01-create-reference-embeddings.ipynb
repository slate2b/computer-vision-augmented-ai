{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e78f5-7a12-4c4b-ab11-6432ff8fa347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running on cpu\n",
    "!pip install numpy pillow tqdm sentence_transformers faiss-cpu\n",
    "# -- OR -- \n",
    "# if running on gpu\n",
    "#!pip install numpy pillow tqdm sentence_transformers faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e49b04-4c95-49fd-b015-9173decef7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "'''\n",
    "This notebook scans images and uses a pretrained CLIP-ViT-B-32 model to create image embeddings, then it creates an \n",
    "FAISS (Facebook AI Similarity Search) HNSW (Hierarchical Navigable Small World) index.  It also creates numpy file that\n",
    "contains the filepaths for the reference images.  The faiss hnsw index file and image filepaths file will be used in the \n",
    "next notebook.\n",
    "'''\n",
    "\n",
    "REF_IMAGE_DIR = \"./reference_images\"\n",
    "INDEX_PATH = \"./reference_embeddings/faiss_hnsw.index\"\n",
    "PATHS_NPY  = \"./reference_embeddings/ref_image_paths.npy\"\n",
    "BATCH_SIZE = 128\n",
    "IMG_EXTS   = (\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\",\".tif\",\".tiff\")\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def load_paths(root):\n",
    "    return [p for p in glob.glob(os.path.join(root, \"**/*\"), recursive=True)\n",
    "            if p.lower().endswith(IMG_EXTS)]\n",
    "\n",
    "\n",
    "def pil_open_rgb(p):\n",
    "    try:\n",
    "        return Image.open(p).convert(\"RGB\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "paths = load_paths(REF_IMAGE_DIR)\n",
    "print(\"Reference images:\", len(paths))\n",
    "np.save(PATHS_NPY, np.array(paths, dtype=object))\n",
    "\n",
    "# model = SentenceTransformer(MODEL_NAME)\n",
    "dim = 512  # ViT-B/32\n",
    "# HNSW with cosine (inner product on normalized vectors)\n",
    "index = faiss.IndexHNSWFlat(dim, 32, faiss.METRIC_INNER_PRODUCT)\n",
    "index.hnsw.efConstruction = 200\n",
    "\n",
    "# Encode in deterministic order and add in the same order\n",
    "batch_imgs, batch_ids = [], []\n",
    "added = 0\n",
    "\n",
    "for rid, p in enumerate(tqdm(paths, desc=\"Embedding+Add\")):\n",
    "    img = pil_open_rgb(p)\n",
    "    if img is None:\n",
    "        # Skip unreadable images to avoid zero vectors corrupting the space\n",
    "        continue\n",
    "    batch_imgs.append(img)\n",
    "    batch_ids.append(rid)\n",
    "\n",
    "    if len(batch_imgs) == BATCH_SIZE:\n",
    "        # batch_imgs can be a list of PIL Images, NumPy arrays, or image file paths\n",
    "        vecs = (model.encode(\n",
    "                    batch_imgs,\n",
    "                    convert_to_numpy=True,\n",
    "                    normalize_embeddings=True,  # L2 normalize\n",
    "                    show_progress_bar=False,\n",
    "                    batch_size=32,  # adjust to your GPU/CPU memory\n",
    "                    ).astype(\"float32\"))\n",
    "        # vecs = model.encode(batch_imgs, convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
    "        index.add(vecs)  # vectors are normalized; IP acts as cosine\n",
    "        batch_imgs.clear(); batch_ids.clear()\n",
    "        added += len(vecs)\n",
    "\n",
    "if batch_imgs:\n",
    "    vecs = model.encode(batch_imgs, convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
    "    index.add(vecs)\n",
    "    added += len(vecs)\n",
    "\n",
    "faiss.write_index(index, INDEX_PATH)\n",
    "print(\"Wrote index:\", INDEX_PATH, \"vectors:\", added)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baea2f7-6568-4113-8eca-d67c77059e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
